{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Place your conda yaml in the below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "conda.yaml"
    ]
   },
   "outputs": [],
   "source": [
    "name: xgb-customer-churn\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - xgboost\n",
    "  - pip\n",
    "  - pip:\n",
    "      - mlflow>=1.6.0\n",
    "      - matplotlib\n",
    "      - boto3\n",
    "      - smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tracking_uri = \"http://107.22.99.180/\"\n",
    "max_depth = 5\n",
    "eta = 0.2\n",
    "gamma = 4\n",
    "min_child_weight = 6\n",
    "eta = 0.2\n",
    "subsample = 0.8\n",
    "silent = 0\n",
    "objective = \"binary:logistic\"\n",
    "num_round = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Imports \n",
    "\n",
    "Place all the imports that you are aware of here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig\n",
    "from sagemaker.model_monitor import DataCaptureConfig, DatasetFormat, DefaultModelMonitor\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Place the standalone functions in the below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(local_data_path):\n",
    "    data = pd.read_csv(local_data_path)\n",
    "    pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "    pd.set_option('display.max_rows', 10)         # Keep the output on one page\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smdebug_hook(out_dir, train_data=None, validation_data=None, frequency=1, collections=None,):\n",
    "\n",
    "    save_config = SaveConfig(save_interval=frequency)\n",
    "    hook = Hook(\n",
    "        out_dir=out_dir,\n",
    "        train_data=train_data,\n",
    "        validation_data=validation_data,\n",
    "        save_config=save_config,\n",
    "        include_collections=collections,\n",
    "    )\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    \"\"\"Load a model. For XGBoost Framework, a default function to load a model is not provided.\n",
    "    Users should provide customized model_fn() in script.\n",
    "    Args:\n",
    "        model_dir: a directory where model is saved.\n",
    "    Returns:\n",
    "        A XGBoost model.\n",
    "        XGBoost model format type.\n",
    "    \"\"\"\n",
    "    model_files = (file for file in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, file)))\n",
    "    model_file = next(model_files)\n",
    "    try:\n",
    "        booster = pickle.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "        format = 'pkl_format'\n",
    "    except Exception as exp_pkl:\n",
    "        try:\n",
    "            booster = xgboost.Booster()\n",
    "            booster.load_model(os.path.join(model_dir, model_file))\n",
    "            format = 'xgb_format'\n",
    "        except Exception as exp_xgb:\n",
    "            print(\"Unable to load model: {} {}\".format(str(exp_pkl), str(exp_xgb)))\n",
    "            import sys\n",
    "            sys.exit(-1)\n",
    "    booster.set_param('nthread', 1)\n",
    "    return booster, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--max-depth\", type=int, default=5)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--gamma\", type=int, default=4)\n",
    "    parser.add_argument(\"--min-child-weight\", type=int, default=6)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--silent\", type=int, default=0)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--num-round\", type=int, default=50)\n",
    "    parser.add_argument(\"--smdebug-path\", type=str, default=None)\n",
    "    parser.add_argument(\"--smdebug-frequency\", type=int, default=1)\n",
    "    parser.add_argument(\"--smdebug-collections\", type=str, default='metrics')\n",
    "    parser.add_argument(\"--output-uri\", type=str, default=\"/opt/ml/output/tensors\",\n",
    "                        help=\"S3 URI of the bucket where tensor data will be stored.\")\n",
    "\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR', '/opt/ml/model'))\n",
    "\n",
    "    print('\\n-------------- Environment Variables -------------\\n')\n",
    "    for key, value in os.environ.items():\n",
    "        print('{}={}'.format(key, value))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize total data\n",
    "\n",
    "Place all of the plots in the following section pertaining to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ignore"
    ]
   },
   "outputs": [],
   "source": [
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Place training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    args = parse_args()\n",
    "    # enable auto logging\n",
    "    mlflow.xgboost.autolog()\n",
    "    train, validation = args.train, args.validation\n",
    "    parse_csv = \"?format=csv&label_column=0\"\n",
    "    dtrain = xgboost.DMatrix(train+parse_csv)\n",
    "    dval = xgboost.DMatrix(validation+parse_csv)\n",
    "\n",
    "    # enable auto logging\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"eta\": args.eta,\n",
    "            \"gamma\": args.gamma,\n",
    "            \"min_child_weight\": args.min_child_weight,\n",
    "            \"subsample\": args.subsample,\n",
    "            \"silent\": args.silent,\n",
    "            \"objective\": args.objective}\n",
    "\n",
    "        # The output_uri is a the URI for the s3 bucket where the metrics will be\n",
    "        # saved.\n",
    "        output_uri = (\n",
    "            args.smdebug_path\n",
    "            if args.smdebug_path is not None\n",
    "            else args.output_uri\n",
    "        )\n",
    "\n",
    "        collections = (\n",
    "            args.smdebug_collections.split(',')\n",
    "            if args.smdebug_collections is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        hook = create_smdebug_hook(\n",
    "            out_dir=output_uri,\n",
    "            frequency=args.smdebug_frequency,\n",
    "            collections=collections,\n",
    "            train_data=dtrain,\n",
    "            validation_data=dval,\n",
    "        )\n",
    "\n",
    "        model = xgboost.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            evals=watchlist,\n",
    "            num_boost_round=args.num_round,\n",
    "            callbacks=[hook])\n",
    "\n",
    "        if not os.path.exists(args.model_dir):\n",
    "            os.makedirs(args.model_dir)\n",
    "\n",
    "        model_location = os.path.join(args.model_dir, 'xgboost-model')\n",
    "        pickle.dump(model, open(model_location, 'wb'))\n",
    "\n",
    "        mlflow.xgboost.log_model(model, 'model', registered_model_name='xgb-customer-churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "training"
    ]
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "try:\n",
    "    run_training()\n",
    "except Exception as e:\n",
    "    logger.exception(\"Unable to execute training\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CodePipeline](codepipeline.png \"Sample CodePipeline View\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "177px",
    "width": "335px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
